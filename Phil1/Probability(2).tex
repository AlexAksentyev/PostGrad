\documentclass[14pt, a4paper, pdftex]{extarticle}

\usepackage{mystyle}
\usepackage{subfiles}



\begin{document}
	
\input{./TitlePageProb.tex}

\tableofcontents
\pagebreak

\section*{Введение}

Любое научное знание основано на неидеальных данных об объекте изучения данной науки. Неидеальность может иметь различную природу: невозможность наблюдения полного набора релевантных факторов, влияющих на изучаеммый процесс; или невозможность прямого наблюдения этих факторов; или фундаментальная неточность измерений --- шум. Необходимость делать достоверные выводы на основе неидеальных данных развилась в отдельную ветвь математики, статистику. В статистике, все неидеальности данных моделируются как стохастические процессы, а теория вероятности является её фундаментальным математическим аппаратом, на идеях которого построены все методы инференции и анализ этих методов.~\cite{Shalizi}

Теория вероятности --- это раздел математики изучающий стохастические процессы. Классической (Колмогоровской) моделью этой теории является пространство с мерой, в котором элементы пространства интерпретируются как возможные результаты эксперимента, события представлены измеряемыми множествами результатов, а вероятность и есть мера на этом пространстве, удовлетворяющая условию нормировки. 

Не смотря на важность роли, которую играет теория вероятности в науке, вопрос о том, \emph{что же такое вероятность}, остаётся по большей степени открытым. Существуют различные интерпретации концепции вероятности: классическая, основанная на принципе индифферентности; логическая, рассматривающая теорию вероятности как обобщение логики; фреквентистская, отождествляющая вероятность с относительной частотой получения результата; пропенсионная, интерпретирующая вероятность как существующую в объективной физической реальности склонность системы к производству определённого результата; субъективистская, полностью отказывающаяся от идеи о вероятности как чём-то существующем вне пределов человеческого разума.~\cite{Hajek}

В данной работе мы рассмотрим подробнее эти интерпретации.

\section{Аксиоматика Колмогорова}

История развития теории вероятности имеет своё начало в работах Паскаля и Ферма, и была мотивирована анализом азартных игр. Тем не менее, её аксиоматизация появилась лишь в 1933 году в немецко-язычной монографии Андрея Николаевича Колмогорова ``Основные понятия теории вероятностей,'' (опубликованной на русском в 1936 году) и стало возможным (по словам самого Колмогорова) только благодаря развитию теории меры французским математиком Анри Лебегом. (В сущности, теория вероятностей входит в класс теорий меры.)

Профессор Колмогоров формализовал вероятность в терминах пространства с мерой. Пространством в математике называется множество с введённой на нём структурой; в случае Колмогоровской теории вероятности, структурой являются алгебра возможных событий эксперимента, определяющая пространство как измеримое, и мера на этой алгебре --- вероятность. Классически, на алгебру событий накладывается дополнительное условие замкнутости относительно счётного объединения её элементов, определяя её, таким образом, как сигма-алгебру.

Последнее условие является предметом споров: нет никаких физических предпосылок моделировать реальные физические процессы бесконечными пространствами; тем не менее, с технической точки зрения, такое ограничение описываемых моделей удобно: именно оно позволяет встроить теорию вероятностей в общий класс теорий меры.

Помимо Колмогоровской, существуют и другие аксиоматические системы, формализующие понятие вероятность,\footnote{Например, алгебра случайных переменных, в которой случайные переменные приняты примитивными концепциями, составляющими $C^*$-алгебру. Определённый на этой алгебре линейный функционал, --- математическое ожидание, --- обращает алгебру в Гильбертово пространство.} но аксиоматика Колмогорова считается классической, и поэтому мы будем рассматривать только те структуры, которые удовлетворяют ей.

\section{Условия приемлемости интерпретации}

Во-первых, интерпретация должна быть моделью формальной системы Колмогорова.
Во-вторых, значения того, что называется вероятностью в данной интерпретации должны быть определяемы, хотя бы в принципе.
В третьих, вероятность должна составлять спектр.
В четвёртых, она должна объяснять почему более вероятные события случаются чаще, чем менее вероятные.
в пятых, она должна объяснять роль вероятности в ограничении уверенности рационального агента.

Так же, было бы неплохо если интерпретация объяснит роль вероятности в индуктивном методе, и позволит различать между индукцией и дедукцией.

\section{Интерпретации}

Существуют три категории классификации интерпретаций вероятности, отличающихся объектом, характеризуемым вероятностью:
\begin{enumerate}
\item вероятность как характеристика отношений между данными и выводами;
\item вероятность как характеристика интеллектуального агента, наблюдающего за случайным процессом;
\item вероятность как характеристика самого процесса.
\end{enumerate}

К первой категории относятся классическая и логическая концепции вероятности, ко второй --- субъективистская, к третьей --- фреквентистская и пропенсионная.

\subsection{Классическая}

Классическая вероятность происходит из работ Лапласа, Паскаля, Бернулли, Гюйгенса, и Лейбница. Классическая вероятность события не мотивирована внешними свидетельствами, и основана лишь на равновесном распределении вероятностей по всем возможным результатам эксперимента, так называемом \emph{принципе индифферентности}. Использование принципа индифферентности мотивировано происхождением теории вероятностей --- анализом азартных игр, в которых условия специально заданы таким образом, чтобы обеспечить равенство вероятности получения любого результата. 

В условиях азартной игры, распределение вероятностей событий \emph{зависит только от структуры} самой \emph{игры}. Вероятность события равна отношению возможных игровых сценариев в которых происходит данное событие, к полному количеству возможных сценариев. Очевидно, что классическая интерпретация не поддерживает бесконечные пространства вероятностей, равно как и иррациональные вероятности, критически важные для квантовой механики.\\

\begin{Remark}[Связь классичесвой и Бэйзиеновской вероятностей]
Можно заметить связь между классической и субъективистской концепциями вероятностей.

Карнап утверждает,~\cite[стр. 5]{Carnap} что использованный в классической теории принцип индифферентности должен интерпретироваться субъективистски. Причиной тому является возникновение парадокса при отождествлении в нём понятия вероятности с объективными частотами выпадения результатов: агент, делающий утверждение о равновероятности результатов процесса \emph{в состоянии неведения}, не является обоснованным; с другой стороны, если он \emph{знает} что один из результатов более вероятен чем другие, но не знает какой именно, это же самое утверждение сделает его непоследовательным. Таким образом, принцип индифферентности не может быть верным. Субъективистская же интерпретация позволяет обойти эту проблему, так как в этом случае у агента нет оснований, если он не знает \emph{какой именно} результат более вероятен, для любого из возможных результатов утверждать что \emph{именно он} более вероятен. Таким образом, принцип индифферентности ломается во фреквентистской интерпретации, но верен в субъективистской.

И действительно, Лаплас утверждает:~\cite[стр. 6]{Laplace}
\begin{quote}
Кривая, по которой движется молекула воздуха, так же определённа, как и орбиты планет; единственная разница между ними та, которая происходит из \emph{нашего незнания}. Вероятность относится частично к этому незнанию, и частично к знанию\dots

Теория шанса состоит из сведения всех событий к определённому числу равновероятных случаев, то есть к таким случаям, о происшествии которых \emph{мы можем быть одинаково неопределены}\dots
\end{quote}

То есть, они считали случайность событий продуктом ограниченности знания человека, и его способности обработать это знание, а не объективным свойством самих событий:~\cite[стр. 4]{Laplace}
\begin{quote}
Представим на секунду интеллект, способный осмыслить все законы движущие природой, и состояния всех объектов, её составляющих, --- интеллект достаточный для обработки всех этих данных, --- такой интеллект описал бы \emph{одной и той же формулой} и движение наикрупнейших тел во вселенной, и самого лёгкого атома; для него, \emph{ничего не было бы неопределённым}\dots
\end{quote}
{\color{white}boom!}
\end{Remark}

Одной из главных проблем классической интерпретации является циркулярность определения вероятности: принцип индифферентности утверждает что в отсутствии свидетельства в пользу одной из конкурирующих возможностей, им нужно приписать равную вероятность; если отложить вопрос о природе `свидетельства' (возможно вероятностной), остаётся рассмотреть две возможности:
\begin{inparaenum}[1)]
\item отсутствие каких либо свидетельств для любого из возможных вариантов, и
\item симметрично сбалансированные свидетельства в пользу альтернативных сценариев.
\end{inparaenum}
На практике, мы никогда не встречаемся с первой возможностью; касательно же второй --- очевидно, что свидетельства в пользу возможных сценариев нужно каким-то образом \emph{взвесить}, чтобы судить об их сбалансированности, и совершенно не очевидно как это можно сделать не ссылаясь на саму определяемую вероятность. Самое естесственное определение симметричности данного свидетельства относительно набора сценариев как раз таки основано на понятии о зависимой вероятности: свидетельство $E$ сбалансировано относительно сценариев $O_1, O_2,\dots O_n$  тогда, и только тогда, когда $P(O_1|~ E) = \cdots = P(O_n|~ E)$.

Для обобщения классической вероятности на бесконечные вероятностные пространства принцип индифферентности заменяется \emph{принципом максимальной энтропии}, известный из теории информации Клода Шеннона.~\cite{Shannon} Энтропия измеряет информативность (или отсутствие таковой) распределения вероятности: чем распределение более сконцентрировано, тем меньше его энтропия, чем оно шире --- тем больше. 

Принцип максимальной энтропии налагает дополнительное условие на распределения вероятности согласованные с нашим априорным знанием о случайном процессе: выбираются только те распределения, которые максимизируют энтропию. Наиболее неинформативным является однородное распределение, приписывающее равную вероятность каждому возможному событию.

Проблема с энтропией начинается при рассмотрении бесконечных пространств вероятности: уже при счётных пространствах однородное распределение приводит к нарушению правил вычисления вероятности, а несчётные пространства не только обнуляют вероятности всех событий, но и подвержены \emph{параметризационным парадоксам}.

Суть параметризационных парадоксов заключается в следующем: допустим фабрика производит кубики льда с длиной ребра от 0 до 1 метра. Какова вероятность произвести кубик с длиной ребра между 0 и $\sfrac12$? Интуитивно, вероятность этого события $\sfrac12$, потому что мы представляем производство кубиков как равновероятный процесс \emph{относительно длины ребра}. Если же переформулировать вопрос в терминах площади грани кубика, вероятность того же события уже $\sfrac14$; если вопрос сформулировать относительно объёма кубика --- вероятность становится $\sfrac18$, и так далее для каждой степени длины ребра. 

Причина парадокса в том, что принцип индифферентности/максимальной энтропии не фиксирует пространство вероятности, в котором описывается стохастический процесс.

Классическая вероятность удовлетворяет Колмогоровской аксиоматике, хотя условие счётной аддитивности вероятности выполняется тривиально, потому что классическая вероятность определена только на конечных пространствах; она проверяема, при условии что соответствующее пространство вероятности определимо; она применима для описания рациональных инференций, если не считать возможную циркулярность в определении вероятности; она совершенно не связывает вероятность с частотой выпадения результата: сколько бы мы не наблюдали что в эксперименте по подбрасыванию монеты чаще выпадает орёл, нежели решка, вероятности обоих событий фиксированы.

Есть ещё одна проблема классической концепции вероятности: исходя из альтернатив, о вероятности которых мы ничего не знаем, принцип идифферентности тем не менее даёт результаты, позволяющие ращличать между комбинациями этих альтернатив; то есть, он позволяет получать информацию из состояния полного незнания.

\subsection{Логическая}

Логическая интерпретация вероятности развивает идею возможности определения вероятности события путём анализа всех возможных сценариев. Логическая концепция вероятности обобщает класическую в двух направлениях:
\begin{inparaenum}[a)]
\item альтернативные сценарии могут иметь неравный вес, и
\item свидетельства в пользу конкурирующих гипотез не обязательно сбалансированы.
\end{inparaenum}

Последнее обобщение является ключевым для сути этой интерпретации: во всех своих видах, логическая интерпретация рассматривает вероятность как импликативное отношение $c(h, e)$ между свидетельством $e$ и гипотезой $h$; при этом импликация обладает степенями поддержки гипотезы свидетельством, одновременно обобщая классическую дедуктивную логику, и предоставляя структуру для формализации процесса индукции.

Наиболее систематично эта интерпретация развита в работах немецекого философа языка и науки Рудольфа Карнапа.~\cite{LogicalProbability} Для формулирования своей интерпретации, Карнап рассматривает класс формальных языков с конечным числом предикатов $\mathcal{L} = (\Set{F_i}[i<\infty], \Set{c_j})$. Наиболее точные высказывания в этих языках называются \emph{описания состояния}, и состоят из связок полных описаний --- формул в которых задействованы \emph{все} предикаты --- всех индивидов (представленных перемеными или константами языка).

Любая мера вероятности $m$ определённая на описаниях состояний автоматически распространяется на все предложения языка (поскольку последние являются связками описаний), и индуцирует функцию подтверждения
\[
	c(h, e) \define \frac{m(h\land e)}{m(e)}.
\]

На данном этапе $m$ (и соответственно $c$) ничем не ограничена, и аргумент Карнапа состоит в том, что индивиды отличаются друг от друга существенным образом не именами, а свойствами, которыми они обладают. Таким опразом появляется понятие \emph{описания структуры}: множества описаний состояния, отличающихся друг от друга лишь именами переменных. 

На примере языка с одним предикатом и тремя индивидами $\mathcal{L} = (F; a,b,c)$, мы имеем восемь возможных состояний и четыре структуры:
\begin{table}[h]
\centering
\begin{tabular}{cc}
\begin{minipage}[t]{.3\linewidth}
Описания состояния
\begin{enumerate}
\item $Fa\land Fb\land Fc$,\label{it:allF}
\item $\lnot Fa\land Fb\land Fc$,\label{it:oneFf}
\item $Fa\land \lnot Fb\land Fc$,\label{it:oneFs}
\item $Fa\land Fb\land \lnot Fc$,\label{it:oneFt}
\item $\lnot Fa \land \lnot Fb\land Fc$,\label{it:twoFf}
\item $\lnot Fa \land Fb \land\lnot Fc$,\label{it:twoFs}
\item $Fa \land\lnot Fb \land\lnot Fc$,\label{it:twoFt}
\item $\lnot Fa \land\lnot Fb\land\lnot Fc$;\label{it:noneF}
\end{enumerate}
\end{minipage}
%
&
%
\begin{minipage}[t]{.3\linewidth}
Описания структуры
\begin{enumerate}
\item $F$ верно для всех: $\Set{1}$,
\item $F$ верно для двух: $\Set{2,3,4}$,
\item $F$ верно для одного: $\Set{5,6,7}$,
\item $F$ не верно: $\Set{8}$.
\end{enumerate}
\end{minipage}
\end{tabular}
\end{table}

Оптимальной, по мнению Карнапа, мерой $m^*$ будет такая, которая приписывает структурам равные доли от единицы, а состояниям --- равные доли от веса структуры. (Хотя нет причин полагать что такое определение меры действительно оптимально, Карнап утверждает что оно наиболее простое и естесственное, и потому предпочтительнее чем другие.) Такая мера придаёт больший вес однородным описаниям состояния, что предположительно соответствует современной индуктивной практике, и отражается на силе подтверждения гипотезы соответствующим свидетельством. (В нашем случае, состояния 1 и 8 имеют вес $\sfrac14$, в то время как все остальные --- $\sfrac{1}{12}$.)

Его дальнейшее обобщение функции подтверждения путём рассмотрения семейств (вместо единичных) предикатов (с добавлением различных аксиом описывающих, например, симметричность этой функции относительно пермутаций предикатов и индивидов), приводит к правилу обновления вероятности, очень схожему по своей структуре с классическим.

Касательно проблем с этой интерпретацией: во-первых, любое общее утверждение о бесконечной структуре никогда не может быть подтверждено со степенью \emph{больше нуля} , независимо от предоставленных свидетельств: $\forall e, c(\forall x\phi(x), e) = 0$. Это проблематично потому, что очевидно, что законы природы, имеющие бесконечное количество возможных инстанциаций, получают \emph{некоторое} подтверждение опытом. 

Во-вторых, использованные Карнапом при определении импликативного отношения аксиомы симметрии едва ли можно назвать тавтологиями. К тому же, добавление новых аксиом, ничем не отличающихся по своей правдоподобности от использованных, нарушает консистентность аксиоматической системы, определяющей вероятность.

В третьих, индуктивная логика должна быть чувствительна к семантике предикатов, в связи с чем чисто синтаксический подход к определению Карнапа не является валидным. 

И самое главное --- обобщение семействами никак не убирает произвольность импликативного отношения, что подрывает смысл этой интерпретации: формализацию индуктивной инференции.

Логическая интерпретация удовлетворяет аксиомам Колмогорова и позволяет практическое определение значений функции подтверждения, однако произвольность в определении этой функции делает невозможным связать её с относительными частотами выпадения результата, или же с субъективной оценкой вероятности события интеллектуальным агентом. В последнем случае, даже при выборе какой-либо конкретной функции, остаётся проблема её нормализации: субъективные вероятности должны быть нормализованы относительно какого-либо свидетельства, которым в случае логической вероятности является утверждение, в котором агент максимально уверен. Проблема состоит в том, что понятие максимально точного утверждения в этих рамках плохо определено.

Касательно применимости в науке: вероятность по Карнапу зависит от языка в котором определяется импликация между утверждениями, который зачастую меняется в процессе развития науки, тем самым подрывая любую теорию подтверждения гипотез основанную на такой концепции вероятности.

\subsection{Субъективистская}

Субъективизм --- это доктрина, в которой вероятность отождествляется со степенью уверенности. Она допускает различие оценки вероятности одной и той же гипотезы разными агентами в присутствии одного и того же набора свидетельств. 

Развитие статистики в конце 19 века сместило фокус внимания с вероятности как средства суждения рационального агента, к вероятности как частоте выпадания результата. Британский экономист Джон Мэйнард Кейнз сделал первые попытки возродить почти забытое на тот момент понятие о вероятности.~\cite{Keynes} Он показал неприменимость классической теории к прикладным задачам вне контекста субъективной вероятности. При этом он не разделял мнение классиков о возможности приписать численное значение вероятности \emph{любой} гипотезы; он считал это возможным только в случае существования детерминированного числа возможных альтернатив, фундаментально неотличимых друг от друга.~\cite[стр. 5]{Carnap}

Для того, чтобы понять что такое вероятность по-субъективистски, нужно понимать что такое \emph{степень уверенности}.

\subsubsection{Степень уверенности}

Классически, вероятность определяется с помощью поведения \emph{рационального агента} при принятии ставок: степень уверенности $p$ агента в верности $A$ это количество условных единиц, с которыми агент готов расстаться если $A$ окажется ложным, при условии ему будет выплачена одна условная единица в случае верности $A$. Аргумент субъективистов состоит в том, что степени уверенности рационального, т.е. логически последовательного, агента удовлетворяют аксиомам Колмогорова, потому что иначе возможно было бы составить серию таких ставок, при которых агент обязательно окажется в долгу.\footnote{
	Альтернативно, в работах Эдвина Джейнса, например, под рациональностью понимается монотонность оценки вероятности при обновлении свидетельств (если при обновлении свидетельства вероятность одной гипотезы пары, рассматриваемой в отдельности, увеличивается, а другой не изменяется, то вероятность пары не убывает) и консистентность, т.е. при возможности нескольких путей рассуждения из одного набора предпосылок, агент должен придти к одному и тому же выводу.
} 
Обратное утверждение также верно: если субъективные оценки вероятности событий агента удовлетворяют правилам вычисления вероятностей, определённым Колмогоровскими аксиомами, невозможно составить такую серию сделок, при которой агент будет обязательно в проигрыше.

Из-за того, что \emph{классическое} субъективистское определение вероятности через поведение агента при делании ставок операционно,\footnote{
	Операционализм основан на идее о том, что если мы не имеем метода измерения концепции, мы не знаем её значение; это теория смысла, которая отождествляет концепцию с некоторым набором операций.~\cite{Operationalism}
}
оно наследует проблемы операционализма в общем,\footnote{
	Одной важной проблемой операционализма является обессмысливание вопроса о валидности метода измерения величины: если понятие равно методу измерения, то тот метод, которым мы определяем данное понятие становится автоматически валидным. То есть, операционные определения слишком ограничивают понятие смысла концепции, сводя его к определению метода измерения концепции, и игнорируя \emph{другие аспекты понятия \textbf{смысл}}.~\cite{Operationalism}
}
и бехейвиоризма в частности: сам факт делания ставки вполне может изменить мнение агента, или мир вокруг него (метод определения величины не определяет значение самой величины);\footnote{
	Определение величины меняет значение величины --- как в квантовой механике.
} или же, ставка может быть сделана на событие, после которого ценность условной единицы будет равна нулю (в этом случае, значение вероятности события не определено); зависимость полезности условной единицы от суммы выигрыша не обязательно должна быть линейной, что исказит оценки вероятности агента (ошибка калибровки метода определения величины, и соответствующая ей, в операционалистической системе, ошибка определения концепции величины). (Бехейвиористская проблема состоит в том, что поведение индивида при делании ставки не отражает его истинное мнение о вероятности выигрыша: он может заблуждаться в оценке своих убеждений, --- если они противоречат социальным нормам, например, и он вынужден самообманываться, --- а может немеренно врать.) Все эти проблемы, тем не менее, происходят из буквальной интерпретации использованных терминов; поэтому следующий шаг в развитии субъективизма заключается в формулировании вероятности в терминах принятия решений на основе их полезности для рационального агента.

\subsubsection{Связь вероятности и полезности}

Рамзи начинает с того, что определяет этически неитральное утверждение: такое утверждение, верность которого не важна для агента сама по себе, только как средство получения полезного результата. Уверенность агента в верности такого утверждения --- это отношене разниц в полезностях следствий верности этого утверждения; оказывается, эта величина удовлетворяет Колмогоровским аксиомам, в случае конечной аддитивности. 

Эта формулировка не решает проблемы определения вероятности через принятие риска при сделках: преференции индивида сильно связаны с его желаниями, зачастую иррациональными и варьирующимися от индивида к индивиду, а значит возникает вопрос о том, \emph{та ли величина} определяется путём наблюдения за поведением индивида в таких ситуациях. (Бехейвиористская проблема также не решена.)

Проблема в определении значений субъективной вероятности через бехейвиористсикй анализ поведения индивида при заключении рискованных сделок кроется в том, что такое поведение сильно зависит от желаний индивида, которые он может не знать сам, тем самым ставя под сомнение удовлетворения этой интерпретацией критерия вычисляемости значений вероятности.

Аргумент о том, что поведение рационального агента управляется его оценками вероятности возможных событий является тавтологией в субъективистской интерпретации, поскольку рациональность решений агента прямо зависит от его оценок вероятности возможных событий. 

\subsubsection{Роль субъективной вероятности в принятии решений}

Субъективная вероятность была придумана на основании анализа поведения рационального агента, но действительно ли эта концепция так хорошо описывает рациональность, как кажется на первый взгляд?

В ортодоксальном субъективизме образца Бруно де Финетти, итальянского математика, придумавшего ``субъективно-операционалистскую'' концепцию вероятности, на вероятность накладываются всего два условия:
\begin{inparaenum}[a)]
\item удовлетворение аксиомам Колмогорова, и
\item правило по обновлению вероятности события, на основании нового свидетельства ($E$): $P_2(X) = P_1(X|E)$, если $P_1(E) > 0$.
\end{inparaenum}

Существует эпистемологическая проблема с использованием такой вероятности: агент, использующий её допускает верность таких утверждений, ложность которых подсказывает здравый смысл. Из этого следует, что ортодоксальный субъективизм де Финетти не описывает эпистемологию рационального агента.

Чтобы повысить рациональность агента, принимающего решения на основе субъективной вероятности, некоторые субъективисты добавляют дополнительное условие --- \emph{регулярность} --- к своей теории вероятности. Суть этого условия заключается в следующем: только противоречия могут иметь вероятность равную нулю. Агент, оперирующий такой вероятностью, допускает возможность всего, что не отрицает дедуктивная логика. 

Критикой такого экстремального субъективизма, примеры которого рассмотрены выше, является то, что вероятность в нём совершенно не связана с окружающей действительностью. Свойство регулярности играет в субъективизме ту же роль, что консистентность в классической логике, и аргумент субъективистов состоит в том, что теория вероятности сродни логике в этом отношении: как логика --- это набор правил для определения консистентности набора утверждений, но не их истинности, так теория вероятности предоставляет аппарат для \emph{проверки консистентности вероятностей} набора  утверждений, но не для \emph{определения} этих вероятностей.~\cite[стр. 4]{Fuchs}

В радикальных формулировках субъективизма, таким образом, вероятность не является частью объективной реальности, а существует только в рамках человеческого разума. Однако Патрик Саппс отмечает,~\cite{Suppes} что такой взгляд на вероятность не согласуется с очевидной объективностью теоретических вероятностей физических процессов, подтверждааемых статистическими, то есть фреквентистскими, данными.

\subsection{Фреквентистская}

Фреквентистская концепция отождествляет вероятность с относительным частотой выпадения результата. В наиболее простой версии, --- конечный фреквентизм, --- вероятность свойства $A$ в \emph{конечном} референсном классе $B$ --- это относительная частота, с которой элементы $B$ обладают свойством $A$.

Конечный фркевентизм был разработан английским логиком Джоном Венном, и является преобладающим взглядом на природу вероятности в современной науке вообще, и в статистике в частности. Именно операционному определению вероятности, даваемому этой интерпретацией, мы обязаны фундаментальному феномену статистических флуктуаций. Вероятность события, в конечной интерпретации, зависит от референсного класса, относительно которого она отсчитывается, что создаёт так называемую `проблему единичного случая' --- по-сути являющуюся проблемой калибровки: для любых двух \emph{конечных} референсных классов, относительная частота, т.е. вероятность, присутствия одного и того же признака будет отличаться.

Для решения проблемы одного случая, некоторые фреквентисты начали определять вероятность с помощью бесконечных реыеренсных классов; так появился \emph{гипотетический фреквентизм}. Его суть заключается в том, что при повторении эксперимента бесконечное число раз, относительная частота события будет стремиться к некоторому пределу; этот предел и называется вероятностью события.

Проблема с определением вероятности через предел последовательности кроется в порядке элементов последловательности. Поскольку порядок не является свойством самого множества, только нашего выбора,~\cite{Russell} элементы одного и того же множества могут быть обращены в последовательности, сходящиеся к разным значениям, т.е. одно и то же событие может иметь произвольную вероятность. Эта проблема называется `проблема референсной последовательности.'

К тому же, одно и то же событие может быть классифицировано разным образом, а значит иметь несколько референсных классов, т.е. несколько значений вероятности, зависящих от категоризации события. Эта проблема называется `проблемой референсного класса.'

Для решения проблемы референсной последовательности, нужно как минимум наложить ограничения на класс рассматриваемых последовательностей. Например, не все последовательности имеют предел в принципе, и потому не подходят для определения вероятности в смысле гипотетического фреквентизма. Попытки решения этой проблемы математиками Рихардам фон Мизесом и, позднее, Алонзо Чёрчем, сформулироваашим аксиомы, определяющие правило выбора референсной последовательности, не разрешили проблему. Их решение основывалось на введении абстрактного математического объекта --- ансамбля, --- свойства которого объяснили бы стабильность в поведении относительных частот в реальных экспериментах: с точки зрения фон Мизеса, любая последовательность событий в реальном эксперименте является начальным сегментом какого-либо ансамлбля. Проблема в том, что для любого свойства существует бесконечное число возможных ансамблей, начальным сегментом которого является данная последовательность результатов эксперимента.

%Нужно отметить, что такие фреквентисты как фон Мизес отрицают проблему единичного случая, утверждая что понятие вероятность имеет смысл только в контексте ансамбля. 

Касательно удовлетворения аксиом Колмогорова: вероятности конечной интерпретации удовлетворяют условию конечной аддитивности вероятности, и, тривиально, счётной, по скольку большинство слагаемых в сумме зануляются, и сумма сводится к конечной. В случае гипотетического фреквентизма, счётная аддитивность нарушается, а значит такая структура не является моделью аксиом Колмогорова.

Относительно возможности вычисления вероятности реальных событий, опять же, конечно-фреквентистская концепция справляется лучше: на практике не возможно провести эксперимент с бесконечным числом повторений, а ни одна конечная подпоследовательность не ограничивает возможный предел бесконечной последовательности, начальным сегментом которой она является; тем более затруднительно ограничить этот предел в случае гипотетического продления в бесконечность физически конечной последовательности событий.

Поразительно, но фреквентизм также не справляется в отношении связи вероятности и относительной частоты выпадения результата: отождествление вероятности и частоты в его конечной вариации делает вероятность события зависимой от конкретного эксперимента, из-за чего происходят флуктуации вероятности; гипотетическая версия вовсе связывает вероятность не с самой частотой, а её гипотетическим пределом, но даже в случае с истинно бесконечными процессами это не обеспечивает равенства между пределом и вероятностью: в принципе, ничего не запрещает монете всегда падать одной и той же стороной вверх в одном гипотетическом эксперименте, и противоположной в другом.


\subsection{Пропенсионная}

Пропенсионная концепция, как и фреквентистская, позиционирует вероятность как реально существующий объект: тенденцию физической системы производить определённый результат.

Существуют различные версии пропенсионизма, отличающися относительно того чему приписывается тенденция: 
\begin{inparaenum}[1)]
\item конкретному физическому \emph{объекту}, участвующему в эксперименте, --- взгляд Чарльза Пирса, одного из основателей статистики, или же
\item \emph{эксперименту} в котором задействован этот объект --- взгляд, развитый Карлом Поппером в попытке придать вероятность уникальным событиям;
\end{inparaenum}
или же родом самой тенденции:
\begin{inparaenum}[1)]
\item \emph{долгосрочные} теории рассматривают тенденции системы производить последовательности результатов с относительными частотами, приблизительно равными вероятностям результатов, и 
\item теории \emph{единичного случая}, в которых тенденция --- это функция системы произвести определённый результат в определённых условиях. 
\end{inparaenum}

В долгосрочных теориях, склонность и вероятность --- разные вещи: склонность системы индуцирует вероятность события, но не измеряется ею, в то время как в теориях единичного случая --- вероятность является мерой тенденции.

Долгосрочные теории, сильно полагаясь на относительные частоты событий, не удовлетворяют вскму набору аксиом Колмогорова по той же причине, что и фрекыентистские теории, в то время как теории единичного случая амбивалентны в этом отношении: всегда можно постулировать удовлетворение Колмогоровским аксиомам как часть определения \emph{тенденции}, однако это не значит что тенденции, в таком понимании этого слова, реально существуют. Теоремы, позволяющие провести аргумент в пользу существования таких тенденций (закон больших чисел, например) основаны на предположениях, которые невозможно ни вывести логически, ни проверить эмпирически.

Частично, проблема заключается в том, что никто не знает что такое \emph{тенденция}; говоря что система обладает некоторым свойством, которое заставляет её производить определённый результат с некоторой частотой в долгосрочной перспективе, и называя это свойство тенденцией, мы совершенно не проясняем природу этого свойства, а из-за этого невозможно произвести тесты, определяющие существуют тенденции в природе или нет. Это относится даже к долгосрочным теориям, поскольку в них практически измеримые частоты --- сущности, отличные от тенденции. Метафизический статус тенденций делает пропенсионную концепцию вероятности малопригодной для эмпирической науки.

Концепция вероятности считается приемлемой, если она способна объяснить роль вероятности в оценках возможностей рационального агента. В своей статье ``Why propensities cannot be probabilities'' философ Пол Хамфриз даёт аргумент почему пропенсионная вероятность не удовлетворяет аксиоматике вероятности. Идея аргумента заключается в том, что из аксиом Колмогорова следует теорема Байеса, которая позволяет обращать условную вероятность; однако, в пропенсионной интерпретации, вероятность является мерой причинно-следственных связей между стимулами и откликами системы, и потому не обратима, как и любая другая причинно-следственная связь. Таким образом, чем бы не являлась `склонность системы производить определённый результат,' эта вещи не может удовлетворять классической аксиоматике теории вероятности. Появление неклассической аксиоматики Джеймса Фетцера и Дональда Ньюта обязано именно этому аргументу. (Однако, для того, чтобы пропенсионная вероятность удовлетворяла классической аксиоматике, достаточно переопределить понятие условной вероятности таким образом, чтобы существование условной вероятности в одну сторону не означало существование обратной условной вероятности, как это сделал Карл Поппер.)

\section*{Заключение}
Мы рассмотрели пять интерпретаций вероятности, существующих на данных момент, и претендующих на название истинной. Три из них --- классическая, логическая, и субъективистская, --- родственны. Действительно, отцы-основатели классической интерпретации рассматривали вероятность как следствие ограниченности человеческого разума, а не как характеристику объективной реальности. Логическая и субъективистская интерпретации, по моему мнению, --- это две ветви развития идей классиков, отличающихся подходами,\footnote{Логическая интерпретация это предельный случай субъективистской, когда внутренними предвзятостями индивидов можно пренебречь.} но разделяющих это фундаментальное представление о природе вероятности. Мы можем видеть, что одни и те же люди, Джон Кейнз и Гарольд Джеффриз, считаются ранними сторонниками и логической~\cite[раз. 3.2 пар. 2]{Hajek}, и субъективистской~\cite[стр. 5--7]{Carnap} интерпретаций.

Контрастом этому семейству концепций служат фреквентистская и пропенсионная интерпретации. Для них, вероятность события имеет тот же метафизический статус, так же реальна, как и само событие. Отличие этих теорий  друг от друга заключается в том, что пропенсионная интерпретация определяет вероятность как характеристику процесса, в то время как фреквентистская --- результатов этого процесса.

Хотелось бы отметить одно обстоятельство, касательно отношения субъективистских и фреквентистской концепций: как говорит Карнап,~\cite[стр. 7]{Carnap} фреквентистская интерпретация вероятности фигурирует \underline{в} научных \underline{утверждениях} (поскольку они об объективных свойствах окружающей действительности), в то время как субъективистская --- в суждениях/утверждениях \underline{об} истинности \underline{этих утверждений}. Таким образом, субъективистская вероятность становится не частью науки, но методологии науки.

\begin{thebibliography}{9}

\bibitem{Shalizi}
Cosma Rohilla Shalizi. “Advanced Data Analysis from an Elementary Point of View,” Spring 2013. \url{http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf}


\bibitem{Hajek}
Alan Hájek. “Interpretations of Probability.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter 2012., 2012. \url{http://plato.stanford.edu/archives/win2012/entries/probability-interpret/}

\bibitem{Carnap}
Rudolf Carnap. “Statistical and Inductive Probability,” 1955. \url{http://fitelson.org/probability/carnap_saip.pdf}

\bibitem{Laplace}
Pierre-Simon Laplace. A Philosophical Essay on Probabilities. Translated by Frederick Wilson Truscott and Frederick Lincoln Emory. 1st ed. John Wiley \& Sons. Accessed April 20, 2016. \url{http://bayes.wustl.edu/Manual/laplace_A_philosophical_essay_on_probabilities.pdf}


\bibitem{LogicalProbability}
Rudolf Carnap. Logical Foundations of Probability. The University of Chicago Press. Accessed April 20, 2016. \url{http://fitelson.org/confirmation/carnap_logical_foundations_of_probability.pdf}


\bibitem{Keynes}
John Maynard Keynes. A Treatise On Probability. Macmillan And Co., 1921. \url{http://archive.org/details/treatiseonprobab007528mbp}


\bibitem{Operationalism}
Hasok Chang. “Operationalism.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Fall 2009., 2009. \url{http://plato.stanford.edu/archives/fall2009/entries/operationalism/}

\bibitem{Shannon}
Claude Elwood Shannon. “A Mathematical Theory of Communication.” The Bell System Technical Journal 27 (October 1948): 379–423, 623–56.

\bibitem{Russell}
Bertrand Russell. Introduction to Mathematical Philosophy. Second. George Allen \& Unwin, 1920.

\bibitem{Fuchs}
Christopher A. Fuchs. “QBism, the Perimeter of Quantum Bayesianism.” arXiv:1003.5209 [quant-Ph], March 26, 2010. \url{http://arxiv.org/abs/1003.5209}

\bibitem{Suppes}
Suppes, Patrick. “The Nature of Probability.” Philosophical Studies 147, no. 1 (January 2010): 89–102. doi:10.1007/s11098-009-9453-z.


%\bibitem{Humphreys}
%Humphreys, Paul. 1985. “Why Propensities Cannot Be Probabilities.” The Philosophical Review 94 (4). [Duke University Press, Philosophical Review]: 557–70. doi:10.2307/2185246.


%\bibitem{UChicago}
%“Introduction to the Mathematical Foundations of Probability Theory,” n.d. http://www.math.uchicago.edu/~lawler/probnotes.pdf.




\end{thebibliography}

\end{document}

